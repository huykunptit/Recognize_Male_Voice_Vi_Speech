#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
·ª®ng d·ª•ng t√¨m ki·∫øm gi·ªçng n√≥i t∆∞∆°ng t·ª± - Phi√™n b·∫£n CLI
Ch·∫°y tr·ª±c ti·∫øp t·ª´ command line, kh√¥ng c·∫ßn web server
"""

import os
import sys
import json
import warnings
from pathlib import Path
from datetime import datetime

import numpy as np
import pandas as pd

# X·ª≠ l√Ω l·ªói numba/librosa tr√™n Windows
LIBROSA_AVAILABLE = False
try:
    import librosa
    LIBROSA_AVAILABLE = True
except (ImportError, Exception) as e:
    print(f"‚ö†Ô∏è  Warning: librosa kh√¥ng th·ªÉ import: {e}")
    print("üí° Gi·∫£i ph√°p:")
    print("   1. C√†i ƒë·∫∑t Visual C++ Redistributable: https://aka.ms/vs/17/release/vc_redist.x64.exe")
    print("   2. Ho·∫∑c ch·∫°y: pip install --upgrade numba llvmlite librosa")
    print("")
    sys.exit(1)

from sklearn.neighbors import NearestNeighbors
from sklearn.preprocessing import StandardScaler
import joblib
from rich.console import Console
from rich.table import Table
from rich.panel import Panel

warnings.filterwarnings('ignore')

# Set encoding for Windows
if sys.platform.startswith('win'):
    import codecs
    try:
        sys.stdout = codecs.getwriter('utf-8')(sys.stdout.detach())
        sys.stderr = codecs.getwriter('utf-8')(sys.stderr.detach())
    except:
        pass

console = Console()

# Config
TRAINED_MODEL_FILE = 'trained_model.json'
SCALER_FILE = 'scaler.joblib'
KNN_MODEL_FILE = 'knn_model.joblib'
SUPER_METADATA_FOLDER = "super_metadata/male_only"
SPEAKER_DB_FILE = "speaker_database.csv"

# Allowed audio extensions
ALLOWED_EXTENSIONS = {'mp3', 'wav', 'm4a', 'flac', 'ogg', 'webm'}

def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS


class VoiceSearchEngine:
    def __init__(self):
        self.super_metadata_folder = SUPER_METADATA_FOLDER
        self.speaker_db_file = SPEAKER_DB_FILE
        self.scaler = None
        self.knn_model = None
        self.feature_columns = None
        self.df_train = None
        self.speaker_db = None
        
    def load_speaker_database(self):
        """Load speaker database v·ªõi t√™n ti·∫øng Vi·ªát"""
        try:
            self.speaker_db = pd.read_csv(self.speaker_db_file, encoding='utf-8')
            console.print(f"[green]‚úì[/] ƒê√£ load {len(self.speaker_db)} speakers t·ª´ database")
            return True
        except Exception as e:
            console.print(f"[red]‚úó[/] L·ªói khi load speaker database: {e}")
            return False
    
    def load_training_data(self):
        """Load v√† merge t·∫•t c·∫£ CSV files t·ª´ super_metadata/male_only"""
        console.print("[cyan]ƒêang load d·ªØ li·ªáu training t·ª´ super_metadata/male_only...[/]")
        all_data = []
        
        csv_files = sorted(Path(self.super_metadata_folder).glob("*.csv"))
        console.print(f"T√¨m th·∫•y {len(csv_files)} file CSV")
        
        for csv_file in csv_files:
            try:
                df = pd.read_csv(csv_file, encoding='utf-8')
                all_data.append(df)
                console.print(f"  - ƒê√£ load {len(df)} records t·ª´ {csv_file.name}")
            except Exception as e:
                console.print(f"  - [red]L·ªói[/] khi load {csv_file.name}: {e}")
        
        if not all_data:
            raise ValueError("Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu training!")
        
        # Merge t·∫•t c·∫£ dataframes
        self.df_train = pd.concat(all_data, ignore_index=True)
        console.print(f"\n[green]T·ªïng c·ªông:[/] {len(self.df_train)} records")
        console.print(f"[green]S·ªë c·ªôt:[/] {len(self.df_train.columns)}")
        
        return True
    
    def get_feature_columns(self):
        """L·∫•y danh s√°ch c√°c c·ªôt features (b·ªè qua metadata columns)"""
        if self.feature_columns is None:
            exclude_cols = ['audio_name', 'dialect', 'gender', 'speaker']
            self.feature_columns = [col for col in self.df_train.columns 
                                   if col not in exclude_cols]
        return self.feature_columns
    
    def train_model(self):
        """Train KNN model t·ª´ d·ªØ li·ªáu training"""
        console.print("\n[bold cyan]=== B·∫Øt ƒë·∫ßu train model ===[/]\n")
        
        # Load d·ªØ li·ªáu
        self.load_training_data()
        self.load_speaker_database()
        
        # L·∫•y feature columns
        feature_cols = self.get_feature_columns()
        console.print(f"[green]S·ªë features:[/] {len(feature_cols)}")
        
        # Chu·∫©n b·ªã d·ªØ li·ªáu training
        X_train = self.df_train[feature_cols].fillna(0).values
        
        # Chu·∫©n h√≥a d·ªØ li·ªáu
        console.print("[cyan]ƒêang chu·∫©n h√≥a d·ªØ li·ªáu...[/]")
        self.scaler = StandardScaler()
        X_train_scaled = self.scaler.fit_transform(X_train)
        
        # Train KNN model
        console.print("[cyan]ƒêang train KNN model (K=10)...[/]")
        self.knn_model = NearestNeighbors(n_neighbors=10, metric='cosine', algorithm='brute')
        self.knn_model.fit(X_train_scaled)
        
        # L∆∞u model v√† scaler
        joblib.dump(self.scaler, SCALER_FILE)
        joblib.dump(self.knn_model, KNN_MODEL_FILE)
        
        # L∆∞u th√¥ng tin training v√†o JSON
        training_info = {
            'trained_at': datetime.now().isoformat(),
            'num_samples': len(self.df_train),
            'num_features': len(feature_cols),
            'feature_columns': feature_cols,
            'model_type': 'KNN',
            'k_neighbors': 10,
            'metric': 'cosine',
            'training_files': [f.name for f in Path(self.super_metadata_folder).glob("*.csv")]
        }
        
        with open(TRAINED_MODEL_FILE, 'w', encoding='utf-8') as f:
            json.dump(training_info, f, ensure_ascii=False, indent=2)
        
        console.print(f"\n[bold green]‚úì ƒê√£ train xong model![/]")
        console.print(f"  - S·ªë samples: {len(self.df_train)}")
        console.print(f"  - S·ªë features: {len(feature_cols)}")
        console.print(f"  - ƒê√£ l∆∞u model v√†o: {TRAINED_MODEL_FILE}")
        
        return training_info
    
    def load_trained_model(self):
        """Load model ƒë√£ train t·ª´ file"""
        try:
            # Load training info
            with open(TRAINED_MODEL_FILE, 'r', encoding='utf-8') as f:
                training_info = json.load(f)
            
            # Load scaler v√† model
            self.scaler = joblib.load(SCALER_FILE)
            self.knn_model = joblib.load(KNN_MODEL_FILE)
            
            # Load d·ªØ li·ªáu training
            self.load_training_data()
            self.load_speaker_database()
            self.feature_columns = training_info['feature_columns']
            
            console.print(f"[green]‚úì[/] ƒê√£ load model ƒë√£ train (trained at: {training_info['trained_at']})")
            return training_info
        except Exception as e:
            console.print(f"[red]‚úó[/] Kh√¥ng t√¨m th·∫•y model ƒë√£ train: {e}")
            return None
    
    def extract_audio_features(self, audio_path):
        """Tr√≠ch xu·∫•t features t·ª´ file audio"""
        global LIBROSA_AVAILABLE
        try:
            if not LIBROSA_AVAILABLE:
                import librosa
                LIBROSA_AVAILABLE = True
            
            # Load audio file
            try:
                y, sr = librosa.load(audio_path, sr=None)
            except Exception as e:
                console.print(f"[yellow]Th·ª≠ l·∫°i v·ªõi duration limit...[/]")
                y, sr = librosa.load(audio_path, sr=None, duration=60)
            
            features = {}
            
            # 1. Pitch
            f0, voiced_flag, voiced_probs = librosa.pyin(y, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7'))
            features['pitch_mean'] = float(np.nanmean(f0)) if not np.all(np.isnan(f0)) else 0.0
            features['pitch_std'] = float(np.nanstd(f0)) if not np.all(np.isnan(f0)) else 0.0
            features['pitch_range'] = float(np.nanmax(f0) - np.nanmin(f0)) if not np.all(np.isnan(f0)) else 0.0
            
            # 2. Spectral Centroid
            spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]
            features['spectral_centroid_mean'] = float(np.mean(spectral_centroids))
            features['spectral_centroid_std'] = float(np.std(spectral_centroids))
            
            # 3. Spectral Rolloff
            spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)[0]
            features['spectral_rolloff_mean'] = float(np.mean(spectral_rolloff))
            features['spectral_rolloff_std'] = float(np.std(spectral_rolloff))
            
            # 4. Zero Crossing Rate
            zcr = librosa.feature.zero_crossing_rate(y)[0]
            features['zcr_mean'] = float(np.mean(zcr))
            features['zcr_std'] = float(np.std(zcr))
            
            # 5. MFCC (13 h·ªá s·ªë)
            mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)
            for i in range(13):
                features[f'mfcc_{i+1}_mean'] = float(np.mean(mfccs[i]))
                features[f'mfcc_{i+1}_std'] = float(np.std(mfccs[i]))
            
            # 6. Chroma
            chroma = librosa.feature.chroma_stft(y=y, sr=sr)
            features['chroma_mean'] = float(np.mean(chroma))
            features['chroma_std'] = float(np.std(chroma))
            
            # 7. Spectral Contrast
            contrast = librosa.feature.spectral_contrast(y=y, sr=sr)
            features['spectral_contrast_mean'] = float(np.mean(contrast))
            features['spectral_contrast_std'] = float(np.std(contrast))
            
            # 8. Tonnetz
            tonnetz = librosa.feature.tonnetz(y=librosa.effects.harmonic(y), sr=sr)
            features['tonnetz_mean'] = float(np.mean(tonnetz))
            features['tonnetz_std'] = float(np.std(tonnetz))
            
            # 9. RMS Energy
            rms = librosa.feature.rms(y=y)[0]
            features['rms_mean'] = float(np.mean(rms))
            features['rms_std'] = float(np.std(rms))
            features['rms_max'] = float(np.max(rms))
            features['rms_min'] = float(np.min(rms))
            
            # 10. Tempo
            tempo, _ = librosa.beat.beat_track(y=y, sr=sr)
            features['tempo'] = float(tempo)
            
            # 11. Duration
            features['duration'] = float(len(y) / sr)
            
            # 12. Loudness
            features['loudness'] = float(20 * np.log10(np.mean(np.abs(y)) + 1e-10))
            features['loudness_peak'] = float(20 * np.log10(np.max(np.abs(y)) + 1e-10))
            
            # 13. Spectral Bandwidth
            spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)[0]
            features['spectral_bandwidth_mean'] = float(np.mean(spectral_bandwidth))
            features['spectral_bandwidth_std'] = float(np.std(spectral_bandwidth))
            
            # 14. Spectral Flatness
            spectral_flatness = librosa.feature.spectral_flatness(y=y)[0]
            features['spectral_flatness_mean'] = float(np.mean(spectral_flatness))
            features['spectral_flatness_std'] = float(np.std(spectral_flatness))
            
            # 15. Harmonic-to-noise ratio
            y_harmonic, y_percussive = librosa.effects.hpss(y)
            hnr = np.mean(20 * np.log10(np.abs(y_harmonic) / (np.abs(y_percussive) + 1e-10)))
            features['hnr'] = float(hnr) if not np.isnan(hnr) and not np.isinf(hnr) else 0.0
            
            # 16. Spectral Slope
            spectral_slope = librosa.feature.spectral_slope(y=y)[0]
            features['spectral_slope_mean'] = float(np.mean(spectral_slope))
            features['spectral_slope_std'] = float(np.std(spectral_slope))
            
            # 17. Spectral Kurtosis
            spectral_kurtosis = librosa.feature.spectral_kurtosis(y=y)[0]
            features['spectral_kurtosis_mean'] = float(np.mean(spectral_kurtosis))
            features['spectral_kurtosis_std'] = float(np.std(spectral_kurtosis))
            
            # 18. Spectral Skewness
            spectral_skewness = librosa.feature.spectral_skewness(y=y)[0]
            features['spectral_skewness_mean'] = float(np.mean(spectral_skewness))
            features['spectral_skewness_std'] = float(np.std(spectral_skewness))
            
            # 19. Onset Strength
            onset_strength = librosa.onset.onset_strength(y=y, sr=sr)
            features['onset_strength_mean'] = float(np.mean(onset_strength))
            features['onset_strength_std'] = float(np.std(onset_strength))
            
            # 20. Spectral Flux
            spectral_flux = librosa.onset.onset_strength(y=y, sr=sr, aggregate=np.median)
            features['spectral_flux'] = float(spectral_flux)
            
            return features
            
        except Exception as e:
            console.print(f"[red]‚úó[/] L·ªói khi tr√≠ch xu·∫•t features: {e}")
            return None
    
    def search_similar_voices(self, audio_path, k=10):
        """T√¨m K gi·ªçng n√≥i t∆∞∆°ng t·ª± nh·∫•t"""
        try:
            if self.knn_model is None or self.scaler is None:
                raise ValueError("Model ch∆∞a ƒë∆∞·ª£c train ho·∫∑c load. Vui l√≤ng train model tr∆∞·ªõc!")
            
            # Tr√≠ch xu·∫•t features
            console.print("[cyan]ƒêang tr√≠ch xu·∫•t features t·ª´ file audio...[/]")
            features = self.extract_audio_features(audio_path)
            if features is None:
                raise ValueError("Kh√¥ng th·ªÉ tr√≠ch xu·∫•t features t·ª´ file audio")
            
            # Chu·∫©n b·ªã feature vector
            feature_cols = self.get_feature_columns()
            if not feature_cols:
                raise ValueError("Kh√¥ng t√¨m th·∫•y feature columns. Vui l√≤ng train model l·∫°i!")
            
            feature_vector = np.array([features.get(col, 0.0) for col in feature_cols]).reshape(1, -1)
            
            # Chu·∫©n h√≥a
            feature_vector_scaled = self.scaler.transform(feature_vector)
            
            # T√¨m K nearest neighbors
            console.print(f"[cyan]ƒêang t√¨m {k} gi·ªçng n√≥i t∆∞∆°ng t·ª± nh·∫•t...[/]")
            distances, indices = self.knn_model.kneighbors(feature_vector_scaled, n_neighbors=k)
            
            # L·∫•y th√¥ng tin c√°c samples t∆∞∆°ng t·ª±
            results = []
            for i, (dist, idx) in enumerate(zip(distances[0], indices[0])):
                sample = self.df_train.iloc[idx]
                
                # T√≠nh similarity percentage
                similarity = (1 - dist) * 100
                
                # L·∫•y th√¥ng tin speaker
                speaker_id = sample['speaker']
                speaker_name = "Unknown"
                if self.speaker_db is not None:
                    speaker_info = self.speaker_db[self.speaker_db['speaker_id'] == speaker_id]
                    if not speaker_info.empty:
                        speaker_name = speaker_info.iloc[0]['vietnamese_name']
                    else:
                        speaker_info = self.speaker_db[self.speaker_db['dialect'] == speaker_id]
                        if not speaker_info.empty:
                            speaker_name = speaker_info.iloc[0]['vietnamese_name']
                
                results.append({
                    'rank': i + 1,
                    'audio_name': sample['audio_name'],
                    'speaker_id': speaker_id,
                    'speaker_name': speaker_name,
                    'similarity': round(similarity, 2),
                    'distance': float(dist),
                    'dialect': sample.get('dialect', 'N/A')
                })
            
            return results
        
        except Exception as e:
            console.print(f"[red]‚úó[/] L·ªói trong search_similar_voices: {e}")
            raise


def display_results(results, audio_file):
    """Hi·ªÉn th·ªã k·∫øt qu·∫£ t√¨m ki·∫øm"""
    console.print(f"\n[bold cyan]K·∫øt qu·∫£ t√¨m ki·∫øm cho:[/] [yellow]{audio_file}[/]\n")
    
    table = Table(show_header=True, header_style="bold magenta")
    table.add_column("Rank", style="cyan", width=6)
    table.add_column("Similarity", style="green", width=12)
    table.add_column("Speaker", style="yellow", width=20)
    table.add_column("Audio Name", style="white", width=40)
    table.add_column("Dialect", style="blue", width=10)
    
    for result in results:
        similarity_color = "green" if result['similarity'] > 80 else "yellow" if result['similarity'] > 60 else "red"
        table.add_row(
            str(result['rank']),
            f"[{similarity_color}]{result['similarity']:.2f}%[/]",
            result['speaker_name'],
            result['audio_name'],
            result['dialect']
        )
    
    console.print(table)


def main():
    """H√†m main"""
    console.print("[bold cyan]·ª®ng d·ª•ng T√¨m ki·∫øm Gi·ªçng n√≥i T∆∞∆°ng t·ª± - CLI[/]\n")
    
    # Kh·ªüi t·∫°o engine
    voice_engine = VoiceSearchEngine()
    
    # Parse arguments
    if len(sys.argv) < 2:
        console.print("[yellow]C√°ch s·ª≠ d·ª•ng:[/]")
        console.print("  python voice_search_cli.py train                    # Train model")
        console.print("  python voice_search_cli.py search <audio_file> [k]  # T√¨m ki·∫øm gi·ªçng n√≥i t∆∞∆°ng t·ª±")
        console.print("  python voice_search_cli.py info                      # Xem th√¥ng tin model")
        sys.exit(1)
    
    command = sys.argv[1].lower()
    
    if command == 'train':
        # Train model
        try:
            voice_engine.train_model()
        except Exception as e:
            console.print(f"[red]‚úó[/] L·ªói khi train: {e}")
            sys.exit(1)
    
    elif command == 'search':
        # T√¨m ki·∫øm
        if len(sys.argv) < 3:
            console.print("[red]‚úó[/] Thi·∫øu t√™n file audio!")
            console.print("  python voice_search_cli.py search <audio_file> [k]")
            sys.exit(1)
        
        audio_file = sys.argv[2]
        k = int(sys.argv[3]) if len(sys.argv) > 3 else 10
        
        # Ki·ªÉm tra file t·ªìn t·∫°i
        if not os.path.exists(audio_file):
            console.print(f"[red]‚úó[/] File kh√¥ng t·ªìn t·∫°i: {audio_file}")
            sys.exit(1)
        
        if not allowed_file(audio_file):
            console.print(f"[red]‚úó[/] ƒê·ªãnh d·∫°ng file kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£!")
            sys.exit(1)
        
        # Load model
        model_info = voice_engine.load_trained_model()
        if model_info is None:
            console.print("[red]‚úó[/] Ch∆∞a c√≥ model. Vui l√≤ng train model tr∆∞·ªõc!")
            console.print("  python voice_search_cli.py train")
            sys.exit(1)
        
        # T√¨m ki·∫øm
        try:
            results = voice_engine.search_similar_voices(audio_file, k=k)
            display_results(results, audio_file)
        except Exception as e:
            console.print(f"[red]‚úó[/] L·ªói: {e}")
            sys.exit(1)
    
    elif command == 'info':
        # Xem th√¥ng tin model
        model_info = voice_engine.load_trained_model()
        if model_info:
            console.print(Panel(
                f"[cyan]Trained at:[/] {model_info['trained_at']}\n"
                f"[cyan]S·ªë samples:[/] {model_info['num_samples']}\n"
                f"[cyan]S·ªë features:[/] {model_info['num_features']}\n"
                f"[cyan]Model type:[/] {model_info['model_type']}\n"
                f"[cyan]K neighbors:[/] {model_info['k_neighbors']}\n"
                f"[cyan]Metric:[/] {model_info['metric']}",
                title="[bold green]Model Information[/]",
                border_style="green"
            ))
        else:
            console.print("[red]‚úó[/] Ch∆∞a c√≥ model ƒë∆∞·ª£c train")
            sys.exit(1)
    
    else:
        console.print(f"[red]‚úó[/] L·ªánh kh√¥ng h·ª£p l·ªá: {command}")
        sys.exit(1)


if __name__ == '__main__':
    main()

