#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
·ª®ng d·ª•ng t√¨m ki·∫øm gi·ªçng n√≥i t∆∞∆°ng t·ª± s·ª≠ d·ª•ng K-Nearest Neighbors
"""

import os
import sys
import json
import warnings
from pathlib import Path
from datetime import datetime

import numpy as np
import pandas as pd

# X·ª≠ l√Ω l·ªói numba/librosa tr√™n Windows
LIBROSA_AVAILABLE = False
try:
    import librosa
    LIBROSA_AVAILABLE = True
except (ImportError, Exception) as e:
    print(f"‚ö†Ô∏è  Warning: librosa kh√¥ng th·ªÉ import: {e}")
    print("üí° Gi·∫£i ph√°p:")
    print("   1. C√†i ƒë·∫∑t Visual C++ Redistributable: https://aka.ms/vs/17/release/vc_redist.x64.exe")
    print("   2. Ho·∫∑c ch·∫°y: pip install --upgrade numba llvmlite librosa")
    print("   3. Xem file FIX_NUMBA_ERROR.md ƒë·ªÉ bi·∫øt th√™m chi ti·∫øt")
    print("")
    # S·∫Ω th·ª≠ import l·∫°i khi c·∫ßn thi·∫øt

from flask import Flask, render_template, request, jsonify, send_from_directory
from werkzeug.utils import secure_filename
from sklearn.neighbors import NearestNeighbors
from sklearn.preprocessing import StandardScaler
import joblib

warnings.filterwarnings('ignore')

# Set encoding for Windows
if sys.platform.startswith('win'):
    import codecs
    try:
        sys.stdout = codecs.getwriter('utf-8')(sys.stdout.detach())
        sys.stderr = codecs.getwriter('utf-8')(sys.stderr.detach())
    except:
        pass

app = Flask(__name__)
app.config['UPLOAD_FOLDER'] = 'uploads'
app.config['MAX_CONTENT_LENGTH'] = 50 * 1024 * 1024  # 50MB max file size
app.config['TRAINED_MODEL_FILE'] = 'trained_model.json'
app.config['SCALER_FILE'] = 'scaler.joblib'
app.config['KNN_MODEL_FILE'] = 'knn_model.joblib'

# T·∫°o folder uploads n·∫øu ch∆∞a c√≥
Path(app.config['UPLOAD_FOLDER']).mkdir(exist_ok=True)

# Allowed audio extensions
ALLOWED_EXTENSIONS = {'mp3', 'wav', 'm4a', 'flac', 'ogg', 'webm'}

def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

class VoiceSearchEngine:
    def __init__(self):
        self.super_metadata_folder = "super_metadata/male_only"
        self.speaker_db_file = "speaker_database.csv"
        self.scaler = None
        self.knn_model = None
        self.feature_columns = None
        self.df_train = None
        self.speaker_db = None
        
    def load_speaker_database(self):
        """Load speaker database v·ªõi t√™n ti·∫øng Vi·ªát"""
        try:
            self.speaker_db = pd.read_csv(self.speaker_db_file, encoding='utf-8')
            print(f"ƒê√£ load {len(self.speaker_db)} speakers t·ª´ database")
            return True
        except Exception as e:
            print(f"L·ªói khi load speaker database: {e}")
            return False
    
    def load_training_data(self):
        """Load v√† merge t·∫•t c·∫£ CSV files t·ª´ super_metadata/male_only"""
        print("ƒêang load d·ªØ li·ªáu training t·ª´ super_metadata/male_only...")
        all_data = []
        
        csv_files = sorted(Path(self.super_metadata_folder).glob("*.csv"))
        print(f"T√¨m th·∫•y {len(csv_files)} file CSV")
        
        for csv_file in csv_files:
            try:
                df = pd.read_csv(csv_file, encoding='utf-8')
                all_data.append(df)
                print(f"  - ƒê√£ load {len(df)} records t·ª´ {csv_file.name}")
            except Exception as e:
                print(f"  - L·ªói khi load {csv_file.name}: {e}")
        
        if not all_data:
            raise ValueError("Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu training!")
        
        # Merge t·∫•t c·∫£ dataframes
        self.df_train = pd.concat(all_data, ignore_index=True)
        print(f"\nT·ªïng c·ªông: {len(self.df_train)} records")
        print(f"S·ªë c·ªôt: {len(self.df_train.columns)}")
        
        return True
    
    def get_feature_columns(self):
        """L·∫•y danh s√°ch c√°c c·ªôt features (b·ªè qua metadata columns)"""
        if self.feature_columns is None:
            exclude_cols = ['audio_name', 'dialect', 'gender', 'speaker']
            self.feature_columns = [col for col in self.df_train.columns 
                                   if col not in exclude_cols]
        return self.feature_columns
    
    def train_model(self):
        """Train KNN model t·ª´ d·ªØ li·ªáu training"""
        print("\n=== B·∫Øt ƒë·∫ßu train model ===")
        
        # Load d·ªØ li·ªáu
        self.load_training_data()
        self.load_speaker_database()
        
        # L·∫•y feature columns
        feature_cols = self.get_feature_columns()
        print(f"S·ªë features: {len(feature_cols)}")
        
        # Chu·∫©n b·ªã d·ªØ li·ªáu training
        X_train = self.df_train[feature_cols].fillna(0).values
        
        # Chu·∫©n h√≥a d·ªØ li·ªáu
        print("ƒêang chu·∫©n h√≥a d·ªØ li·ªáu...")
        self.scaler = StandardScaler()
        X_train_scaled = self.scaler.fit_transform(X_train)
        
        # Train KNN model
        print("ƒêang train KNN model (K=10)...")
        self.knn_model = NearestNeighbors(n_neighbors=10, metric='cosine', algorithm='brute')
        self.knn_model.fit(X_train_scaled)
        
        # L∆∞u model v√† scaler
        joblib.dump(self.scaler, app.config['SCALER_FILE'])
        joblib.dump(self.knn_model, app.config['KNN_MODEL_FILE'])
        
        # L∆∞u th√¥ng tin training v√†o JSON
        training_info = {
            'trained_at': datetime.now().isoformat(),
            'num_samples': len(self.df_train),
            'num_features': len(feature_cols),
            'feature_columns': feature_cols,
            'model_type': 'KNN',
            'k_neighbors': 10,
            'metric': 'cosine',
            'training_files': [f.name for f in Path(self.super_metadata_folder).glob("*.csv")]
        }
        
        with open(app.config['TRAINED_MODEL_FILE'], 'w', encoding='utf-8') as f:
            json.dump(training_info, f, ensure_ascii=False, indent=2)
        
        print(f"\n‚úì ƒê√£ train xong model!")
        print(f"  - S·ªë samples: {len(self.df_train)}")
        print(f"  - S·ªë features: {len(feature_cols)}")
        print(f"  - ƒê√£ l∆∞u model v√†o: {app.config['TRAINED_MODEL_FILE']}")
        
        return training_info
    
    def load_trained_model(self):
        """Load model ƒë√£ train t·ª´ file"""
        try:
            # Load training info
            with open(app.config['TRAINED_MODEL_FILE'], 'r', encoding='utf-8') as f:
                training_info = json.load(f)
            
            # Load scaler v√† model
            self.scaler = joblib.load(app.config['SCALER_FILE'])
            self.knn_model = joblib.load(app.config['KNN_MODEL_FILE'])
            
            # Load d·ªØ li·ªáu training
            self.load_training_data()
            self.load_speaker_database()
            self.feature_columns = training_info['feature_columns']
            
            print(f"‚úì ƒê√£ load model ƒë√£ train (trained at: {training_info['trained_at']})")
            return training_info
        except Exception as e:
            print(f"Kh√¥ng t√¨m th·∫•y model ƒë√£ train: {e}")
            return None
    
    def extract_audio_features(self, audio_path):
        """Tr√≠ch xu·∫•t features t·ª´ file audio (gi·ªëng nh∆∞ trong create_super_metadata.py)"""
        global LIBROSA_AVAILABLE
        try:
            # Ki·ªÉm tra librosa c√≥ s·∫µn kh√¥ng
            if not LIBROSA_AVAILABLE:
                try:
                    import librosa
                    LIBROSA_AVAILABLE = True
                except ImportError:
                    raise ImportError("librosa kh√¥ng th·ªÉ s·ª≠ d·ª•ng. Vui l√≤ng c√†i ƒë·∫∑t l·∫°i: pip install --upgrade numba llvmlite librosa")
            
            # Load audio file v·ªõi error handling t·ªët h∆°n
            try:
                y, sr = librosa.load(audio_path, sr=None)
            except Exception as e:
                # Th·ª≠ l·∫°i v·ªõi duration limit n·∫øu file qu√° d√†i
                print(f"L·ªói khi load audio l·∫ßn ƒë·∫ßu: {e}")
                try:
                    y, sr = librosa.load(audio_path, sr=None, duration=60)  # Gi·ªõi h·∫°n 60s
                except Exception as e2:
                    raise Exception(f"Kh√¥ng th·ªÉ load file audio: {str(e2)}. C√≥ th·ªÉ file kh√¥ng ƒë√∫ng ƒë·ªãnh d·∫°ng ho·∫∑c b·ªã h·ªèng.")
            
            features = {}
            
            # 1. Pitch
            f0, voiced_flag, voiced_probs = librosa.pyin(y, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7'))
            features['pitch_mean'] = float(np.nanmean(f0)) if not np.all(np.isnan(f0)) else 0.0
            features['pitch_std'] = float(np.nanstd(f0)) if not np.all(np.isnan(f0)) else 0.0
            features['pitch_range'] = float(np.nanmax(f0) - np.nanmin(f0)) if not np.all(np.isnan(f0)) else 0.0
            
            # 2. Spectral Centroid
            spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]
            features['spectral_centroid_mean'] = float(np.mean(spectral_centroids))
            features['spectral_centroid_std'] = float(np.std(spectral_centroids))
            
            # 3. Spectral Rolloff
            spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)[0]
            features['spectral_rolloff_mean'] = float(np.mean(spectral_rolloff))
            features['spectral_rolloff_std'] = float(np.std(spectral_rolloff))
            
            # 4. Zero Crossing Rate
            zcr = librosa.feature.zero_crossing_rate(y)[0]
            features['zcr_mean'] = float(np.mean(zcr))
            features['zcr_std'] = float(np.std(zcr))
            
            # 5. MFCC (13 h·ªá s·ªë)
            mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)
            for i in range(13):
                features[f'mfcc_{i+1}_mean'] = float(np.mean(mfccs[i]))
                features[f'mfcc_{i+1}_std'] = float(np.std(mfccs[i]))
            
            # 6. Chroma
            chroma = librosa.feature.chroma_stft(y=y, sr=sr)
            features['chroma_mean'] = float(np.mean(chroma))
            features['chroma_std'] = float(np.std(chroma))
            
            # 7. Spectral Contrast
            contrast = librosa.feature.spectral_contrast(y=y, sr=sr)
            features['spectral_contrast_mean'] = float(np.mean(contrast))
            features['spectral_contrast_std'] = float(np.std(contrast))
            
            # 8. Tonnetz
            tonnetz = librosa.feature.tonnetz(y=librosa.effects.harmonic(y), sr=sr)
            features['tonnetz_mean'] = float(np.mean(tonnetz))
            features['tonnetz_std'] = float(np.std(tonnetz))
            
            # 9. RMS Energy
            rms = librosa.feature.rms(y=y)[0]
            features['rms_mean'] = float(np.mean(rms))
            features['rms_std'] = float(np.std(rms))
            features['rms_max'] = float(np.max(rms))
            features['rms_min'] = float(np.min(rms))
            
            # 10. Tempo
            tempo, _ = librosa.beat.beat_track(y=y, sr=sr)
            features['tempo'] = float(tempo)
            
            # 11. Duration
            features['duration'] = float(len(y) / sr)
            
            # 12. Loudness
            features['loudness'] = float(20 * np.log10(np.mean(np.abs(y)) + 1e-10))
            features['loudness_peak'] = float(20 * np.log10(np.max(np.abs(y)) + 1e-10))
            
            # 13. Spectral Bandwidth
            spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)[0]
            features['spectral_bandwidth_mean'] = float(np.mean(spectral_bandwidth))
            features['spectral_bandwidth_std'] = float(np.std(spectral_bandwidth))
            
            # 14. Spectral Flatness
            spectral_flatness = librosa.feature.spectral_flatness(y=y)[0]
            features['spectral_flatness_mean'] = float(np.mean(spectral_flatness))
            features['spectral_flatness_std'] = float(np.std(spectral_flatness))
            
            # 15. Harmonic-to-noise ratio
            y_harmonic, y_percussive = librosa.effects.hpss(y)
            hnr = np.mean(20 * np.log10(np.abs(y_harmonic) / (np.abs(y_percussive) + 1e-10)))
            features['hnr'] = float(hnr) if not np.isnan(hnr) and not np.isinf(hnr) else 0.0
            
            # 16. Spectral Slope
            spectral_slope = librosa.feature.spectral_slope(y=y)[0]
            features['spectral_slope_mean'] = float(np.mean(spectral_slope))
            features['spectral_slope_std'] = float(np.std(spectral_slope))
            
            # 17. Spectral Kurtosis
            spectral_kurtosis = librosa.feature.spectral_kurtosis(y=y)[0]
            features['spectral_kurtosis_mean'] = float(np.mean(spectral_kurtosis))
            features['spectral_kurtosis_std'] = float(np.std(spectral_kurtosis))
            
            # 18. Spectral Skewness
            spectral_skewness = librosa.feature.spectral_skewness(y=y)[0]
            features['spectral_skewness_mean'] = float(np.mean(spectral_skewness))
            features['spectral_skewness_std'] = float(np.std(spectral_skewness))
            
            # 19. Onset Strength
            onset_strength = librosa.onset.onset_strength(y=y, sr=sr)
            features['onset_strength_mean'] = float(np.mean(onset_strength))
            features['onset_strength_std'] = float(np.std(onset_strength))
            
            # 20. Spectral Flux
            spectral_flux = librosa.onset.onset_strength(y=y, sr=sr, aggregate=np.median)
            features['spectral_flux'] = float(spectral_flux)
            
            return features
            
        except Exception as e:
            import traceback
            error_msg = f"L·ªói khi tr√≠ch xu·∫•t features t·ª´ {audio_path}: {str(e)}"
            print(error_msg)
            print(traceback.format_exc())
            return None
    
    def search_similar_voices(self, audio_path, k=10):
        """T√¨m K gi·ªçng n√≥i t∆∞∆°ng t·ª± nh·∫•t"""
        try:
            # Ki·ªÉm tra model ƒë√£ ƒë∆∞·ª£c load ch∆∞a
            if self.knn_model is None or self.scaler is None:
                raise ValueError("Model ch∆∞a ƒë∆∞·ª£c train ho·∫∑c load. Vui l√≤ng train model tr∆∞·ªõc!")
            
            # Tr√≠ch xu·∫•t features t·ª´ audio
            features = self.extract_audio_features(audio_path)
            if features is None:
                raise ValueError("Kh√¥ng th·ªÉ tr√≠ch xu·∫•t features t·ª´ file audio")
            
            # Chu·∫©n b·ªã feature vector
            feature_cols = self.get_feature_columns()
            if not feature_cols:
                raise ValueError("Kh√¥ng t√¨m th·∫•y feature columns. Vui l√≤ng train model l·∫°i!")
            
            feature_vector = np.array([features.get(col, 0.0) for col in feature_cols]).reshape(1, -1)
            
            # Chu·∫©n h√≥a
            try:
                feature_vector_scaled = self.scaler.transform(feature_vector)
            except Exception as e:
                raise ValueError(f"L·ªói khi chu·∫©n h√≥a features: {str(e)}")
            
            # T√¨m K nearest neighbors
            try:
                distances, indices = self.knn_model.kneighbors(feature_vector_scaled, n_neighbors=k)
            except Exception as e:
                raise ValueError(f"L·ªói khi t√¨m ki·∫øm neighbors: {str(e)}")
            
            # L·∫•y th√¥ng tin c√°c samples t∆∞∆°ng t·ª±
            results = []
            for i, (dist, idx) in enumerate(zip(distances[0], indices[0])):
                sample = self.df_train.iloc[idx]
                
                # T√≠nh similarity percentage (cosine distance -> similarity)
                similarity = (1 - dist) * 100
                
                # L·∫•y th√¥ng tin speaker
                speaker_id = sample['speaker']
                speaker_name = "Unknown"
                if self.speaker_db is not None:
                    # Map speaker t·ª´ training data v·ªõi speaker_id trong database
                    speaker_info = self.speaker_db[self.speaker_db['speaker_id'] == speaker_id]
                    if not speaker_info.empty:
                        speaker_name = speaker_info.iloc[0]['vietnamese_name']
                    else:
                        # Th·ª≠ t√¨m v·ªõi dialect n·∫øu kh√¥ng t√¨m th·∫•y
                        speaker_info = self.speaker_db[self.speaker_db['dialect'] == speaker_id]
                        if not speaker_info.empty:
                            speaker_name = speaker_info.iloc[0]['vietnamese_name']
                
                results.append({
                    'rank': i + 1,
                    'audio_name': sample['audio_name'],
                    'speaker_id': speaker_id,
                    'speaker_name': speaker_name,
                    'similarity': round(similarity, 2),
                    'distance': float(dist),
                    'dialect': sample.get('dialect', 'N/A')
                })
            
            return results
        
        except Exception as e:
            import traceback
            error_msg = f"L·ªói trong search_similar_voices: {str(e)}"
            print(error_msg)
            print(traceback.format_exc())
            raise

# Kh·ªüi t·∫°o Voice Search Engine
voice_engine = VoiceSearchEngine()

@app.route('/')
def index():
    """Trang ch·ªß"""
    # Ki·ªÉm tra xem ƒë√£ c√≥ model ch∆∞a
    model_info = voice_engine.load_trained_model()
    return render_template('index.html', model_info=model_info)

@app.route('/train', methods=['POST'])
def train():
    """Train model t·ª´ d·ªØ li·ªáu training"""
    try:
        training_info = voice_engine.train_model()
        return jsonify({
            'success': True,
            'message': 'ƒê√£ train model th√†nh c√¥ng!',
            'training_info': training_info
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'L·ªói khi train: {str(e)}'
        }), 500

@app.route('/upload', methods=['POST'])
def upload_file():
    """Upload v√† x·ª≠ l√Ω file audio"""
    print(f"\n=== Upload Request ===")
    print(f"Method: {request.method}")
    print(f"Content-Type: {request.content_type}")
    print(f"Files: {list(request.files.keys())}")
    print(f"Form: {dict(request.form)}")
    
    if 'file' not in request.files:
        print("ERROR: Kh√¥ng c√≥ 'file' trong request.files")
        return jsonify({'success': False, 'message': 'Kh√¥ng c√≥ file ƒë∆∞·ª£c upload'}), 400
    
    file = request.files['file']
    print(f"File object: {file}")
    print(f"Filename: {file.filename}")
    print(f"Content-Type: {file.content_type}")
    
    if file.filename == '':
        print("ERROR: Filename r·ªóng")
        return jsonify({'success': False, 'message': 'Ch∆∞a ch·ªçn file'}), 400
    
    if not allowed_file(file.filename):
        print(f"ERROR: ƒê·ªãnh d·∫°ng kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£: {file.filename}")
        return jsonify({'success': False, 'message': f'ƒê·ªãnh d·∫°ng file kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£: {file.filename.rsplit(".", 1)[-1] if "." in file.filename else "unknown"}'}), 400
    
    # Ki·ªÉm tra model ƒë√£ ƒë∆∞·ª£c train ch∆∞a
    if voice_engine.knn_model is None:
        model_info = voice_engine.load_trained_model()
        if model_info is None:
            return jsonify({
                'success': False,
                'message': 'Ch∆∞a c√≥ model. Vui l√≤ng train model tr∆∞·ªõc!'
            }), 400
    
    try:
        # L∆∞u file
        filename = secure_filename(file.filename)
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        file.save(filepath)
        
        print(f"ƒê√£ l∆∞u file: {filepath}")
        print(f"K√≠ch th∆∞·ªõc file: {os.path.getsize(filepath)} bytes")
        
        # Ki·ªÉm tra file t·ªìn t·∫°i
        if not os.path.exists(filepath):
            return jsonify({'success': False, 'message': 'File kh√¥ng t·ªìn t·∫°i sau khi l∆∞u'}), 500
        
        # T√¨m ki·∫øm gi·ªçng n√≥i t∆∞∆°ng t·ª±
        k = int(request.form.get('k', 10))
        print(f"B·∫Øt ƒë·∫ßu t√¨m ki·∫øm v·ªõi K={k}")
        
        results = voice_engine.search_similar_voices(filepath, k=k)
        
        if results is None:
            return jsonify({'success': False, 'message': 'L·ªói khi x·ª≠ l√Ω file audio. Vui l√≤ng ki·ªÉm tra ƒë·ªãnh d·∫°ng file.'}), 500
        
        print(f"T√¨m th·∫•y {len(results)} k·∫øt qu·∫£")
        
        return jsonify({
            'success': True,
            'filename': filename,
            'results': results
        })
        
    except ValueError as e:
        # L·ªói validation
        return jsonify({'success': False, 'message': str(e)}), 400
    except Exception as e:
        import traceback
        error_msg = f'L·ªói khi x·ª≠ l√Ω: {str(e)}'
        print(error_msg)
        print(traceback.format_exc())
        return jsonify({'success': False, 'message': error_msg}), 500

@app.route('/model_info', methods=['GET'])
def model_info():
    """L·∫•y th√¥ng tin model"""
    model_info = voice_engine.load_trained_model()
    if model_info:
        return jsonify({'success': True, 'model_info': model_info})
    else:
        return jsonify({'success': False, 'message': 'Ch∆∞a c√≥ model ƒë∆∞·ª£c train'})

if __name__ == '__main__':
    print("=" * 60)
    print("·ª®ng d·ª•ng T√¨m ki·∫øm Gi·ªçng n√≥i T∆∞∆°ng t·ª±")
    print("=" * 60)
    print("\nƒêang kh·ªüi ƒë·ªông server...")
    print("Truy c·∫≠p: http://localhost:5000")
    print("\nNh·∫•n Ctrl+C ƒë·ªÉ d·ª´ng server")
    print("=" * 60)
    
    app.run(debug=True, host='0.0.0.0', port=5000)

